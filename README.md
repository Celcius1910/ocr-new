# KTP OCR System (YOLO + Donut + PaddleOCR)

Production-ready OCR system for Indonesian KTP (Kartu Tanda Penduduk) with YOLO detection, Donut OCR for body text, and optional PaddleOCR for robust header parsing (Provinsi/Kota).

> Quick links: [Start here ‚Üí Quick Start (fresh clone)](#quick-start-fresh-clone--models-via-git-lfs) ¬∑ [Installation](#installation) ¬∑ [Usage](#usage) ¬∑ [Models & Git LFS](#models--git-lfs) ¬∑ [Wilayah Lookup](#data-wilayah-lookup-kelurahankecamatan)

## Features

‚úÖ **Multi-mode operation**: File, Folder, Camera  
‚úÖ **GPU Acceleration**: CUDA support for YOLO and Donut (2.1x speedup)  
‚úÖ **Advanced preprocessing**: CLAHE, sharpening, denoising  
‚úÖ **Orientation detection**: Auto-rotate vertical KTPs  
‚úÖ **Confidence scoring**: Multi-level validation (YOLO, OCR tokens, per-field)  
‚úÖ **Enhanced parsing**: 30+ cities/kelurahan database, fuzzy matching  
‚úÖ **Header fields**: Extracts `provinsi` and `kota/kabupaten` from header via PaddleOCR (single-region) with typo-fixes and fuzzy canonicalization  
‚úÖ **Thresholded outputs**: Only fields meeting per-field confidence thresholds are included  
‚úÖ **JSON output**: API-ready structured results

## System Requirements

### Hardware Requirements

**Minimum (CPU-only mode)**:

- Processor: Intel i5 or AMD Ryzen 5 (or equivalent)
- RAM: 8 GB
- Storage: 5 GB free space
- Processing speed: ~4.3 seconds per image

**Recommended (GPU-accelerated)**:

- Processor: Intel i7 or AMD Ryzen 7 (or better)
- RAM: 16 GB
- GPU: NVIDIA GPU with CUDA support (RTX 3060 or better)
- VRAM: 4 GB minimum (8 GB recommended)
- Storage: 10 GB free space
- Processing speed: ~2.1 seconds per image (2.1x faster than CPU)

**Tested Configuration**:

- GPU: NVIDIA GeForce RTX 4070 SUPER (12GB VRAM)
- Driver: 581.57 (CUDA 13.0)
- Processing speed: ~2.06 seconds per image
- Throughput: 0.49 images/second

### Software Requirements

- **Operating System**: Windows 10/11 (64-bit)
- **Python**: 3.8 - 3.11 (tested on 3.11)
- **CUDA Toolkit**: 12.1 or higher (for GPU mode)
- **NVIDIA Driver**: Latest version supporting your GPU

## Installation

### Option 1: CPU-Only Mode (Quick Start)

Untuk instalasi cepat tanpa GPU acceleration:

```powershell
# 1. Clone atau download repository ini
cd "c:\OCR AXA\afi-ocr-ktp-code"

# 2. Buat virtual environment
python -m venv .venv_system

# 3. Aktifkan virtual environment
.\.venv_system\Scripts\Activate.ps1

# 4. Install dependencies (CPU version)
pip install -r requirements.txt

# 5. Verifikasi instalasi
python scripts\diagnostics\check_cuda.py
```

### Option 2: GPU-Accelerated Mode (Recommended)

Untuk performa terbaik dengan NVIDIA GPU:

#### Step 1: Verifikasi GPU dan Driver

```powershell
# Cek apakah NVIDIA GPU terdeteksi
nvidia-smi
```

Jika command tidak ditemukan, install [NVIDIA Driver terbaru](https://www.nvidia.com/Download/index.aspx).

#### Step 2: Install Python dan Virtual Environment

```powershell
# 1. Buat virtual environment
python -m venv .venv_system

# 2. Aktifkan virtual environment
.\.venv_system\Scripts\Activate.ps1
```

#### Step 3: Install Dependencies

**Opsi A: Automated GPU Installation (Recommended)**

```powershell
# Jalankan automated installer
.\install_gpu.ps1
```

Script ini akan:

- ‚úÖ Uninstall PyTorch CPU version
- ‚úÖ Install PyTorch GPU (CUDA 12.1)
- ‚úÖ Install PaddlePaddle GPU
- ‚úÖ Verifikasi CUDA availability
- ‚úÖ Test GPU dengan check_cuda.py

**Opsi B: Manual Installation**

```powershell
# 1. Uninstall CPU versions (jika ada)
pip uninstall torch torchvision torchaudio paddlepaddle -y

# 2. Install PyTorch dengan CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. Install dependencies lainnya
pip install ultralytics transformers sentencepiece opencv-python pillow

# 4. (Optional) Install PaddlePaddle GPU
# Note: Saat ini ada compatibility issue dengan PyTorch 2.5+
# Gunakan CPU version atau skip jika tidak butuh header OCR
pip install paddlepaddle-gpu==2.6.2 -f https://www.paddlepaddle.org.cn/whl/windows/mkl/avx/stable.html
```

#### Step 4: Verifikasi GPU Installation

```powershell
# Jalankan diagnostic tool
python scripts\diagnostics\check_cuda.py
```

Output yang diharapkan:

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   CUDA and GPU Environment Check     ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚úì NVIDIA Driver: 581.57 (CUDA Version: 13.0)
‚úì PyTorch CUDA: Available
  - CUDA Version: 12.1
  - Device: cuda:0 (NVIDIA GeForce RTX 4070 SUPER)
  - Compute Capability: 8.9

‚ö†Ô∏è PaddlePaddle GPU: Import error (optional component)
  Note: Main pipeline (YOLO + Donut) works without PaddleOCR

‚úì Ultralytics YOLO: Installed (version 8.3.206)
```

#### Step 5: Test GPU Processing

```powershell
# Test dengan sample images
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\test_gpu.json --yolo-device cuda --donut-device cuda
```

Cek output log untuk konfirmasi:

```
Using devices -> Donut: cuda, YOLO: cuda, Paddle GPU: False
Torch CUDA available: True | torch.version.cuda: 12.1
Torch GPU device: NVIDIA GeForce RTX 4070 SUPER
Donut model actual device: cuda:0
```

### Troubleshooting Installation

**Problem: PyTorch tidak detect CUDA**

```powershell
# Cek versi PyTorch yang terinstall
python -c "import torch; print(torch.__version__)"

# Jika muncul "+cpu", install ulang GPU version:
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**Problem: PaddlePaddle import error**

```
ValueError: generic_type: type '_gpuDeviceProperties' is already registered!
```

**Solusi**: Ini adalah known compatibility issue antara PaddlePaddle 2.6+ dan PyTorch 2.5+. Pipeline tetap bisa jalan tanpa PaddleOCR:

- Header OCR akan disabled
- Field `provinsi` dan `kota` tetap bisa extracted dari Donut (dengan akurasi lebih rendah)
- Alternatif: Gunakan PaddlePaddle CPU version atau tunggu update compatibility

**Problem: CUDA out of memory**

```
RuntimeError: CUDA out of memory
```

**Solusi**:

1. Reduce batch size (tidak applicable untuk single image mode)
2. Gunakan GPU dengan VRAM lebih besar (minimum 4GB)
3. Fallback ke CPU mode: `--yolo-device cpu --donut-device cpu`

## Git Operations

### Updating Your Local Repository

Untuk mendapatkan perubahan terbaru dari GitHub repository:

```powershell
# 1. Cek status repository lokal
git status

# 2. Fetch perubahan dari remote (tanpa merge)
git fetch origin

# 3. Pull perubahan dan merge ke branch lokal
git pull origin main
```

**Perbedaan `fetch` vs `pull`**:

- `git fetch origin`: Download perubahan dari remote, tapi **tidak** merge ke branch lokal. Aman untuk cek perubahan tanpa mengubah kode lokal.
- `git pull origin main`: Download **dan** merge perubahan ke branch lokal. Equivalent dengan `git fetch` + `git merge`.

### Committing and Pushing Changes

Jika Anda melakukan perubahan pada kode dan ingin menyimpan ke repository:

```powershell
# 1. Cek file yang berubah
git status

# 2. Stage file yang ingin di-commit
git add run_ocr.py                    # Satu file
git add *.py                          # Semua file Python
git add .                             # Semua file yang berubah

# 3. Commit dengan pesan yang jelas
git commit -m "fix: deskripsi perubahan yang dilakukan"

# 4. Push ke GitHub
git push origin main
```

**Best Practices untuk Commit Messages**:

- `fix: ...` - Untuk bug fixes
- `feat: ...` - Untuk fitur baru
- `docs: ...` - Untuk perubahan dokumentasi
- `chore: ...` - Untuk maintenance tasks (update dependencies, etc.)
- `refactor: ...` - Untuk code refactoring tanpa perubahan fungsionalitas

### Checking Commit History

```powershell
# Lihat 5 commit terakhir
git log --oneline -5

# Lihat detail commit tertentu
git show <commit-hash>

# Lihat perubahan yang belum di-commit
git diff
```

### Handling Merge Conflicts

Jika terjadi conflict saat `git pull`:

```powershell
# 1. Lihat file yang conflict
git status

# 2. Edit file yang conflict secara manual (remove conflict markers)
#    Cari tanda <<<<<<<, =======, >>>>>>>

# 3. Stage file yang sudah di-resolve
git add <file-yang-conflict>

# 4. Commit merge
git commit -m "merge: resolve conflicts"

# 5. Push hasil merge
git push origin main
```

**Tips**: Gunakan VS Code untuk resolve conflicts. VS Code otomatis detect conflict dan menyediakan UI untuk memilih "Accept Current" / "Accept Incoming" / "Accept Both".

### Important Notes

‚ö†Ô∏è **File yang di-ignore oleh Git** (sesuai `.gitignore`):

- `models/` folder - Model files terlalu besar (790MB+), tidak di-track oleh git
- `outputs/` folder - Hasil OCR bersifat temporary
- `.venv/`, `.venv_system/` - Virtual environment tidak perlu di-commit
- `__pycache__/`, `*.pyc` - Python cache files

üí° **Setup Model Files** setelah clone/pull:

Karena `models/` folder tidak ada di git, Anda perlu copy manual:

```powershell
# Copy dari backup location atau old project
Copy-Item -Path "C:\afi-ocr-ktp-code\donut-ktp-v3" -Destination "models\" -Recurse -Force
Copy-Item -Path "C:\afi-ocr-ktp-code\best.pt" -Destination "models\" -Force

# Verifikasi model files ada
dir models\
```

## Data: Wilayah Lookup (Kelurahan/Kecamatan)

Sistem menggunakan dataset administrasi Indonesia (CSV) dan fuzzy matching untuk melengkapi `kel_desa`/`kecamatan` jika label tidak terbaca.

- Modul: `wilayah_lookup.py`
- Dataset: `wilayah_administrasi_indonesia/csv/` (delimiter `;`, UTF-8)
- Integrasi: dieksekusi di `run_ocr.py` setelah `kota` berhasil dideteksi dari header OCR

Cara update dataset CSV dan contoh penggunaan ada di dokumen: `docs/wilayah_lookup.md`.

## Config: Thresholds & OCR/Fuzzy Settings

Semua threshold dan knob terkait OCR/fuzzy sekarang terpusat di `config.py` agar mudah di-tune tanpa mengubah banyak file.

- Lokasi: `config.py`
- Utama yang bisa diubah:
  - FIELD_THRESHOLDS: ambang minimal confidence per field (0.0‚Äì1.0)
    - Contoh default: alamat=0.50, kel_desa=0.55, kecamatan=0.55, nik=0.90, rt_rw=0.80, dst.
  - EASY_HEADER_MIN_CONF: 0.30 (min conf token EasyOCR untuk header PROVINSI/KOTA)
  - EASY_BODY_MIN_CONF: 0.40 (min conf token EasyOCR untuk body fallback)
  - HEADER_CROP_RATIO: 0.40 (rasio tinggi header dari crop YOLO)
  - BODY*ROI*[X/Y]\_\*: ROI body fokus (biasanya area kel/ kec)
  - FUZZY_WILAYAH_THRESHOLD: 0.70 (threshold fuzzy matching kelurahan/kecamatan)

Catatan penting:

- `run_ocr.py` dan `process_ktp_json.py` otomatis mengambil nilai dari `config.py`.
- `run_ocr.py` tetap menghormati CLI override untuk alamat (opsional) bila digunakan.
- Ubah angka di `config.py`, simpan, lalu jalankan ulang perintah untuk mencoba tuning baru.

Contoh tweak cepat:

- Naikkan ketatnya kelurahan/kecamatan: set `kel_desa=0.60` dan `kecamatan=0.60` di `FIELD_THRESHOLDS`.
- Perketat fuzzy: set `FUZZY_WILAYAH_THRESHOLD=0.75` untuk mengurangi false positive.
- Longgarkan EasyOCR body: turunkan `EASY_BODY_MIN_CONF` ke `0.35` jika teks body sering putus.

## Models & Git LFS

Model besar (mis. `models/best.pt`, `models/donut-ktp-v3/model.safetensors`) sebaiknya ditrack dengan [Git LFS](https://git-lfs.com/) agar push/pull efisien.

Langkah cepat (PowerShell):

```powershell
# 1) Pastikan Git LFS terpasang
git lfs version
git lfs install

# 2) Track tipe file model (root repo)
git lfs track "*.pt"
git lfs track "*.safetensors"
git lfs track "*.onnx"
git lfs track "*.bin"

# 3) Commit aturan LFS
git add .gitattributes
git commit -m "chore(lfs): track model files via Git LFS"
git push

# 4) Tambahkan/push model (opsional)
git add models/best.pt models/donut-ktp-v3/model.safetensors
git commit -m "feat(models): add weights via LFS"
git push
```

Catatan:

- `.gitignore` telah disesuaikan agar folder `models/` tidak diabaikan, sehingga file model dapat dipush via LFS.
- Jika tidak ingin membagikan model di GitHub, biarkan file tetap lokal (abaikan langkah 4).

## Quick Start (fresh clone) ‚Äî models via Git LFS

Langkah ringkas untuk clone repo, menarik model via Git LFS, dan langsung jalanin inference.

```powershell
# 1) Clone repo dan aktifkan Git LFS
git lfs version
git clone https://github.com/Celcius1910/ocr-new.git
cd ocr-new
git lfs install
git lfs pull   # pastikan file model terunduh penuh, bukan pointer

# 2) Verifikasi model weights ada dan size-nya > 0 (bukan pointer LFS)
Get-Item models/best.pt | Select-Object Name,Length
Get-Item models/donut-ktp-v3/model.safetensors | Select-Object Name,Length

# 3) Buat & aktifkan virtual environment
python -m venv .venv_system
 .\.venv_system\Scripts\Activate.ps1
pip install -r requirements.txt

# 4) (Opsional) Setup GPU
# Cara cepat (recommended, otomatis menginstall PyTorch CUDA):
.\install_gpu.ps1

# 5) Jalankan OCR
# a) Single image (ganti path ke file KTP Anda)
python run_ocr.py --mode file --input path\to\ktp.jpg --output outputs\result.json

# b) Folder (ganti path ke folder gambar Anda)
python run_ocr.py --mode folder --input path\to\folder --output outputs\results.json

# (Opsional) Gunakan GPU
python run_ocr.py --mode folder --input path\to\folder --output outputs\results.json --yolo-device cuda --donut-device cuda
```

Ekspektasi log (contoh):

```
Using devices -> Donut: cuda, YOLO: cuda, Paddle GPU: False
Torch CUDA available: True | torch.version.cuda: 12.1
Donut model actual device: cuda:0
```

Troubleshooting cepat:

- Jika ukuran `models/best.pt` atau `model.safetensors` sangat kecil (‚â§ 150 bytes), berarti masih pointer LFS ‚Üí jalankan `git lfs pull`.
- Jika import error PyTorch CUDA, jalankan `.\install_gpu.ps1` atau install PyTorch CUDA 12.1 secara manual.
- Jika input folder tidak ada, ganti `--input` ke folder/file milik Anda.

## Usage

### Quick Start Examples

Pastikan virtual environment sudah diaktifkan:

```powershell
.\.venv_system\Scripts\Activate.ps1
```

#### 1. Process Single Image (File Mode)

```powershell
# CPU mode (default)
python run_ocr.py --mode file --input path\to\ktp.jpg --output outputs\result.json

# GPU mode (2.1x faster)
python run_ocr.py --mode file --input path\to\ktp.jpg --output outputs\result.json --yolo-device cuda --donut-device cuda
```

**Output**: `outputs\result.json` dengan struktur JSON lengkap (lihat [JSON Output Structure](#json-output-structure)).

#### 2. Batch Process Folder (Folder Mode)

```powershell
# CPU mode
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json

# GPU mode (recommended untuk batch processing)
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cuda --donut-device cuda
```

**Output**: `outputs\results.json` dengan array hasil per image + timing statistics.

#### 3. Interactive Camera Mode

```powershell
# Default webcam (CPU mode)
python run_ocr.py --mode camera

# With GPU acceleration
python run_ocr.py --mode camera --yolo-device cuda --donut-device cuda
```

**Controls**:

- Press `c` untuk capture dan process KTP
- Press `q` untuk quit

**Tips**:

- Jika webcam tidak terbuka, ubah `CAMERA_INDEX` di `run_ocr.py` (0 ‚Üí 1 atau 2)
- Untuk DroidCam: set `CAMERA_INDEX = None` dan sesuaikan `DROIDCAM_URL`

### Device Selection Options

System mendukung flexible device selection untuk setiap component:

```powershell
# Full GPU mode (fastest, recommended jika CUDA available)
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cuda --donut-device cuda

# Full CPU mode (fallback jika GPU tidak tersedia)
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cpu --donut-device cpu

# Hybrid mode: YOLO di GPU, Donut di CPU (balance performance dan VRAM usage)
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cuda --donut-device cpu

# Auto-detect mode (default jika tidak specify --*-device)
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json
```

**Device Options**:

- `cuda` - Use NVIDIA GPU (requires CUDA installation)
- `cpu` - Force CPU mode
- `auto` - Auto-detect (use GPU if available, fallback to CPU)

### Advanced Options

#### Enable PaddleOCR Fallback

Secara default, PaddleOCR fallback **disabled** untuk performa maksimal. Aktifkan jika butuh OCR tambahan untuk field yang missed oleh Donut:

```powershell
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --enable-fallback
```

**Catatan**:

- Fallback menambah ~2x processing time
- Hanya aktif jika PaddleOCR berhasil di-import (tidak ada compatibility issue)

#### Custom Confidence Thresholds

Edit `process_ktp_json.py`, function `process_image()`, bagian `FIELD_CONFIDENCE_THRESHOLDS`:

```python
FIELD_CONFIDENCE_THRESHOLDS = {
    "nik": 0.9,          # Sangat strict untuk NIK
    "nama": 0.7,         # Cukup strict untuk nama
    "provinsi": 0.8,     # Strict untuk header fields
    "kota": 0.7,
    "alamat": 0.6,       # Lebih lenient untuk free-text
    "rt_rw": 0.7,
   "kel_desa": 0.55,
   "kecamatan": 0.55,
    "agama": 0.8,
    "pekerjaan": 0.7,
    "status_perkawinan": 0.7,
    # ... dan lainnya
}
```

Field dengan confidence di bawah threshold akan return `null` di output JSON.

### Performance Benchmarks

Berikut adalah hasil benchmark pada 7 sample images (datasets/sample_ocr_ktp_axa):

| Configuration                   | Total Time | Per Image | Throughput | Speedup  |
| ------------------------------- | ---------- | --------- | ---------- | -------- |
| **CPU Mode** (Intel i7/Ryzen 7) | 30.21s     | ~4.32s    | 0.23 img/s | 1.0x     |
| **GPU Mode** (RTX 4070 SUPER)   | 14.39s     | ~2.06s    | 0.49 img/s | **2.1x** |

**Test Configuration**:

- Hardware: NVIDIA GeForce RTX 4070 SUPER (12GB VRAM)
- Software: PyTorch 2.5.1+cu121, CUDA 12.1
- Models: YOLOv8n (best.pt), Donut (donut-ktp-v3)
- Dataset: 7 KTP images, mixed quality and orientations
- Commands:

  ```powershell
  # CPU benchmark
  python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.cpu.json --yolo-device cpu --donut-device cpu

  # GPU benchmark
  python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.gpu.json --yolo-device cuda --donut-device cuda
  ```

**First-Run Cache Effect**:

- First GPU run: ~4.5s total (model loading overhead)
- Subsequent runs: ~14.4s (stable performance)
- Production: Use warm-up dummy inference untuk pre-load models

**Recommendations**:

- **Single/Few Images**: GPU overhead tidak signifikan, CPU acceptable
- **Batch Processing (10+ images)**: GPU strongly recommended (2.1x faster)
- **Real-time Camera**: GPU untuk responsive experience (<2s per capture)
- **High-Volume API**: GPU + batch processing + model caching

Detail lengkap di [BENCHMARK.md](docs/BENCHMARK.md).

### Diagnostic Tools

#### Check CUDA Status

```powershell
python scripts\diagnostics\check_cuda.py
```

Output meliputi:

- ‚úì/‚úó NVIDIA Driver version
- ‚úì/‚úó PyTorch CUDA availability
- ‚úì/‚úó GPU device name dan compute capability
- ‚úì/‚úó PaddlePaddle GPU status

#### Inspect Header OCR Results

```powershell
python tools\diagnostics\show_headers.py outputs\results.json
```

Display header OCR text dan parsed provinsi/kota per image.

#### Analyze Processing Timing

```powershell
python tools\diagnostics\show_timing.py
```

Show timing breakdown per image (jika tersedia di metadata).

#### YOLO-only Live Viewer

```powershell
python tools\diagnostics\process_yolo_optimized.py
```

View real-time YOLO detection tanpa OCR (untuk test detection dan FPS).

## Supported Modes

| Mode     | Description                                       | Use Case                       |
| -------- | ------------------------------------------------- | ------------------------------ |
| `file`   | Process single image                              | API integration, single upload |
| `folder` | Batch process multiple images                     | Testing, bulk processing       |
| `camera` | Interactive capture (press `c`=capture, `q`=quit) | Live scanning, demo            |

## JSON Output Structure

### Single File Mode

```json
{
  "status": "success",
  "timestamp": "2025-11-01T10:30:00",
  "metadata": {
    "processing_time": "2.34s",
    "image_size": "960x624",
    "crop_size": "960x624",
    "raw_ocr_text": "...",
    "header_ocr_text": "...",
    "header_provinsi_line": "PROVINSI JAWA TIMUR",
    "header_kota_line": "KOTA SURABAYA",
    "file_name": "ktp.jpg",
    "confidence": {
      "yolo_confidence": 0.95,
      "ocr_avg_token_prob": null,
      "ocr_token_count": null,
      "overall": null
    },
    "field_confidence": {
      "nik": 1.0,
      "nama": 0.9,
      "provinsi": 1.0,
      "kota": 0.9,
      "tempat_lahir": 0.7,
      "tanggal_lahir": 1.0,
      "jenis_kelamin": 1.0,
      "alamat": 1.0,
      "rt_rw": 1.0,
      "kel_desa": 0.9,
      "kecamatan": 0.9,
      "agama": 1.0,
      "status_perkawinan": 1.0,
      "pekerjaan": 0.0,
      "kewarganegaraan": 1.0,
      "berlaku_hingga": 1.0
    },
    "field_thresholds": {
      "nik": 0.9,
      "nama": 0.7,
      "provinsi": 0.8,
      "kota": 0.7,
      "...": 0.6
    }
  },
  "data": {
    "nik": "1234567890123456",
    "nama": "JOHN DOE",
    "provinsi": "DKI JAKARTA",
    "kota": "JAKARTA",
    "tempat_lahir": "JAKARTA",
    "tanggal_lahir": "01-01-1990",
    "jenis_kelamin": "LAKI-LAKI",
    "alamat": "JL. EXAMPLE NO. 123",
    "rt_rw": "001/002",
    "kel_desa": "MENTENG",
    "kecamatan": "MENTENG",
    "agama": "ISLAM",
    "status_perkawinan": "KAWIN",
    "pekerjaan": null,
    "kewarganegaraan": "WNI",
    "berlaku_hingga": "SEUMUR HIDUP"
  }
}
```

### Folder Mode (with timing statistics)

```json
{
  "status": "success",
  "timestamp": "2025-11-01T15:15:16",
  "metadata": {
    "total_images": 19,
    "successful": 17,
    "failed": 2,
    "total_processing_time": "54.87s",
    "avg_time_per_image": "3.22s",
    "min_time": "2.53s",
    "max_time": "4.21s"
  },
  "results": [
    {
      "status": "success",
      "metadata": {
        "processing_time": "3.75s",
        "file_name": "ktp_001.jpg",
        ...
      },
      "data": { ... }
    },
    {
      "status": "error",
      "metadata": {
        "processing_time": "0.12s",
        "file_name": "ktp_invalid.jpg",
        "error": "No KTP card detected"
      },
      "data": null
    }
  ]
}
```

**Field Descriptions**:

- `status`: "success" atau "error"
- `metadata.processing_time`: Waktu proses per image (seconds)
- `metadata.confidence`: Multi-level confidence scores
  - `yolo_confidence`: Detection confidence (0.0-1.0)
  - `ocr_avg_token_prob`: Average token probability dari Donut
  - `overall`: Combined confidence score
- `metadata.field_confidence`: Per-field confidence scores (0.0-1.0)
- `data`: Extracted KTP fields (null jika confidence < threshold)

**Confidence Thresholds**:
Fields dengan confidence di bawah threshold akan return `null`:

- `nik`: 0.9 (sangat strict)
- `nama`, `provinsi`: 0.7-0.8
- `alamat`: 0.5, `kel_desa` & `kecamatan`: 0.55 (lebih lenient untuk free-text)

## Supported Modes

| Mode     | Description                                       | Use Case                       |
| -------- | ------------------------------------------------- | ------------------------------ |
| `file`   | Process single image                              | API integration, single upload |
| `folder` | Batch process multiple images                     | Testing, bulk processing       |
| `camera` | Interactive capture (press `c`=capture, `q`=quit) | Live scanning, demo            |

## Project Structure

```
afi-ocr-ktp-code/
‚îú‚îÄ‚îÄ run_ocr.py                      # Main CLI entry point
‚îú‚îÄ‚îÄ process_ktp_json.py             # Core OCR & parsing logic
‚îú‚îÄ‚îÄ install_gpu.ps1                 # Automated GPU installer (Windows)
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ README.md                       # This file
‚îú‚îÄ‚îÄ models/                         # Model files
‚îÇ   ‚îú‚îÄ‚îÄ best.pt                     # YOLOv8n model for KTP detection
‚îÇ   ‚îî‚îÄ‚îÄ donut-ktp-v3/               # Donut OCR model
‚îÇ       ‚îú‚îÄ‚îÄ config.json
‚îÇ       ‚îú‚îÄ‚îÄ model.safetensors
‚îÇ       ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ docs/                           # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ BENCHMARK.md                # Performance benchmarks (CPU vs GPU)
‚îÇ   ‚îî‚îÄ‚îÄ IMPROVEMENTS.md             # Changelog and improvements
‚îú‚îÄ‚îÄ scripts/                        # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ diagnostics/                # Diagnostic tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_cuda.py           # GPU diagnostic tool
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_agama.py          # Agama field checker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_alamat.py         # Alamat field checker
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ check_pekerjaan.py      # Pekerjaan field checker
‚îÇ   ‚îî‚îÄ‚îÄ testing/                    # Testing and development scripts
‚îÇ       ‚îú‚îÄ‚îÄ benchmark_yolo.py       # YOLO performance benchmark
‚îÇ       ‚îú‚îÄ‚îÄ list_cameras.py         # List available cameras
‚îÇ       ‚îú‚îÄ‚îÄ test_droidcam.py        # DroidCam connection test
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ datasets/                       # Training and test data
‚îÇ   ‚îú‚îÄ‚îÄ data.yaml
‚îÇ   ‚îú‚îÄ‚îÄ train/, valid/, test/       # YOLO format datasets
‚îÇ   ‚îî‚îÄ‚îÄ sample_ocr_ktp_axa/         # Sample images for testing
‚îú‚îÄ‚îÄ outputs/                        # JSON output files
‚îÇ   ‚îú‚îÄ‚îÄ results.json
‚îÇ   ‚îú‚îÄ‚îÄ results.cpu.json
‚îÇ   ‚îî‚îÄ‚îÄ results.gpu.json
‚îú‚îÄ‚îÄ runs/                           # YOLO training runs
‚îÇ   ‚îî‚îÄ‚îÄ detect/
‚îÇ       ‚îú‚îÄ‚îÄ train/
‚îÇ       ‚îú‚îÄ‚îÄ train2/
‚îÇ       ‚îî‚îÄ‚îÄ train3/
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ diagnostics/
        ‚îú‚îÄ‚îÄ show_headers.py         # Display header OCR results
        ‚îú‚îÄ‚îÄ show_timing.py          # Analyze processing timing
        ‚îî‚îÄ‚îÄ process_yolo_optimized.py  # YOLO-only live viewer
```

## Key Files

- **run_ocr.py**: Main entry point dengan CLI arguments (mode, device selection, thresholds)
- **process_ktp_json.py**: Core logic untuk:
  - YOLO detection (crop KTP from image)
  - Donut OCR (extract raw text)
  - PaddleOCR header parsing (optional, untuk provinsi/kota)
  - Field parsing dengan confidence scoring
  - Fuzzy matching dan canonicalization
- **scripts/diagnostics/check_cuda.py**: Diagnostic tool untuk verify GPU installation
- **install_gpu.ps1**: Automated script untuk install PyTorch GPU + PaddlePaddle GPU

## Configuration

### Default Settings (process_ktp_json.py)

#### Confidence Thresholds

```python
FIELD_CONFIDENCE_THRESHOLDS = {
    "nik": 0.9,               # Strict untuk NIK (16 digit)
    "nama": 0.7,              # Standard untuk nama
    "provinsi": 0.8,          # Strict untuk header field
    "kota": 0.7,
    "tempat_lahir": 0.7,
    "tanggal_lahir": 0.8,
    "jenis_kelamin": 0.9,     # High confidence untuk enum
    "alamat": 0.6,            # Lenient untuk free-text
    "rt_rw": 0.7,
   "kel_desa": 0.55,
   "kecamatan": 0.55,
    "agama": 0.8,
    "status_perkawinan": 0.7,
    "pekerjaan": 0.7,
    "kewarganegaraan": 0.8,
    "berlaku_hingga": 0.7
}
```

Edit values ini untuk adjust strictness per field.

#### YOLO Detection Threshold

```python
# In process_image() function
results = yolo_model(input_img, conf=0.5, verbose=False)
```

`conf=0.5`: Minimum confidence untuk accept detection (0.0-1.0).

#### Camera Settings (run_ocr.py)

```python
CAMERA_INDEX = 0          # 0=default webcam, 1/2=external camera
DROIDCAM_URL = None       # Set ke "http://192.168.x.x:4747/video" untuk DroidCam
```

### Environment Variables

Optional environment variables untuk advanced configuration:

```powershell
# Set default device
$env:YOLO_DEVICE = "cuda"
$env:DONUT_DEVICE = "cuda"

# Enable debug logging
$env:OCR_DEBUG = "1"
```

## Troubleshooting

### GPU dan CUDA Issues

#### Problem: PyTorch tidak detect CUDA setelah install

**Symptoms**:

```
Torch CUDA available: False
```

**Solutions**:

1. **Verify CUDA installation**:

   ```powershell
   nvidia-smi
   python -c "import torch; print(torch.version.cuda)"
   ```

2. **Reinstall PyTorch GPU**:

   ```powershell
   pip uninstall torch torchvision torchaudio -y
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

3. **Check NVIDIA driver version**:

   - Driver minimal: 450.80.02+ (untuk CUDA 11.0+)
   - Update driver di [NVIDIA Downloads](https://www.nvidia.com/Download/index.aspx)

4. **Verify dengan check_cuda.py**:
   ```powershell
   python scripts\diagnostics\check_cuda.py
   ```

#### Problem: PaddlePaddle import error

**Symptoms**:

```
ValueError: generic_type: type '_gpuDeviceProperties' is already registered!
```

**Cause**: Compatibility issue antara PaddlePaddle 2.6+ dan PyTorch 2.5+

**Impact**:

- Header OCR tidak available (provinsi/kota extraction affected)
- Main pipeline (YOLO + Donut) tetap berfungsi normal
- Field provinsi/kota bisa extracted dari Donut raw text (lower accuracy)

**Solutions**:

**Option 1: Continue without PaddleOCR (Recommended)**

- Sistem sudah handle gracefully
- Main OCR tetap berfungsi
- Provinsi/kota extracted dari Donut (fallback method)

**Option 2: Use PaddlePaddle CPU version**

```powershell
pip uninstall paddlepaddle paddlepaddle-gpu -y
pip install paddlepaddle==3.0.0b1  # CPU version
```

**Option 3: Use older PaddlePaddle GPU**

```powershell
pip uninstall paddlepaddle paddlepaddle-gpu -y
pip install paddlepaddle-gpu==2.5.2 -f https://www.paddlepaddle.org.cn/whl/windows/mkl/avx/stable.html
```

**Option 4: Wait for compatibility fix**

- Monitor PaddlePaddle releases untuk PyTorch 2.5+ compatibility

#### Problem: CUDA out of memory

**Symptoms**:

```
RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB
```

**Solutions**:

1. **Use hybrid mode** (YOLO GPU, Donut CPU):

   ```powershell
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cuda --donut-device cpu
   ```

2. **Fallback to CPU mode**:

   ```powershell
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cpu --donut-device cpu
   ```

3. **Close other GPU applications** (browser, games, etc.)

4. **Upgrade GPU** (minimum 4GB VRAM recommended, 8GB ideal)

### OCR Accuracy Issues

#### Problem: Provinsi/Kota field kosong atau salah

**Possible Causes**:

1. PaddleOCR tidak available (import error)
2. Header KTP tidak standard (layout berbeda)
3. Image quality rendah (blur, skewed, low resolution)

**Solutions**:

1. **Check header OCR results**:

   ```powershell
   python tools\diagnostics\show_headers.py outputs\results.json
   ```

   Review `header_ocr_text`, `header_provinsi_line`, `header_kota_line`

2. **Enable fallback** (jika PaddleOCR available):

   ```powershell
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --enable-fallback
   ```

3. **Improve image quality**:

   - Minimal resolution: 640x480
   - Good lighting (avoid shadows)
   - Flat surface (tidak curved atau wrinkled)
   - Straight angle (tidak miring >15¬∞)

4. **Lower confidence threshold**:
   Edit `process_ktp_json.py`:
   ```python
   FIELD_CONFIDENCE_THRESHOLDS = {
       "provinsi": 0.6,  # dari 0.8
       "kota": 0.5,      # dari 0.7
   }
   ```

#### Problem: Field `pekerjaan` selalu null

**Cause**: Donut model tidak trained untuk field ini (known limitation)

**Solutions**:

1. **Enable PaddleOCR fallback** (jika available):

   ```powershell
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --enable-fallback
   ```

2. **Manual extraction** dari `raw_ocr_text`:

   ```python
   import json
   with open("outputs/results.json") as f:
       data = json.load(f)
       raw_text = data["metadata"]["raw_ocr_text"]
       # Extract pekerjaan dari raw text (position-based atau keyword matching)
   ```

3. **Retrain Donut model** dengan annotated dataset yang include field pekerjaan:
   - Perlu minimal 100+ annotated samples
   - Fine-tune `donut-ktp-v3` model dengan field baru
   - Resources: [Donut Documentation](https://github.com/clovaai/donut)

#### Problem: Alamat tidak lengkap atau terpotong

**Possible Causes**:

1. Alamat terlalu panjang (>2 lines)
2. RT/RW tidak detected sebagai end marker
3. Confidence threshold terlalu strict

**Solutions**:

1. **Check raw OCR text**:

   ```powershell
   python -c "import json; data = json.load(open('outputs/results.json')); print(data['metadata']['raw_ocr_text'])"
   ```

2. **Lower confidence threshold**:

   ```python
   FIELD_CONFIDENCE_THRESHOLDS = {
       "alamat": 0.4,  # dari 0.6
   }
   ```

3. **Review alamat extraction logic** di `process_ktp_json.py`:
   - Function `extract_alamat_with_confidence()`
   - 3-stage fallback: RT/RW anchor ‚Üí line break ‚Üí first line
   - End markers: RT/RW, "KEL/DESA", "KECAMATAN"

### Camera Issues

#### Problem: Webcam tidak terbuka

**Symptoms**:

```
Error: Could not open camera
```

**Solutions**:

1. **Check camera index**:
   Edit `run_ocr.py`:

   ```python
   CAMERA_INDEX = 1  # Try 1, 2, 3 untuk external cameras
   ```

2. **Test with OpenCV**:

   ```python
   import cv2
   cap = cv2.VideoCapture(0)  # Test index 0, 1, 2
   print(cap.isOpened())
   cap.release()
   ```

3. **DroidCam setup** (use phone as webcam):

   ```python
   # In run_ocr.py
   CAMERA_INDEX = None
   DROIDCAM_URL = "http://192.168.1.100:4747/video"  # Replace dengan IP phone
   ```

4. **Check camera permissions**:
   - Windows Settings ‚Üí Privacy ‚Üí Camera
   - Allow Python.exe to access camera

#### Problem: Camera lag atau FPS rendah

**Solutions**:

1. **Use GPU mode**:

   ```powershell
   python run_ocr.py --mode camera --yolo-device cuda --donut-device cuda
   ```

2. **Reduce camera resolution**:
   Edit `run_ocr.py`:

   ```python
   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
   ```

3. **Use YOLO-only viewer** untuk test detection speed:
   ```powershell
   python tools\diagnostics\process_yolo_optimized.py
   ```

### Performance Issues

#### Problem: Processing terlalu lambat (>5s per image)

**Solutions**:

1. **Enable GPU acceleration** (2.1x speedup):

   ```powershell
   # Install PyTorch GPU jika belum
   .\install_gpu.ps1

   # Run dengan GPU
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --yolo-device cuda --donut-device cuda
   ```

2. **Disable fallback** (2x faster):

   ```powershell
   # Default: fallback disabled
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json

   # Jika enable-fallback=True di config, override:
   # Edit process_ktp_json.py, set enable_fallback=False
   ```

3. **Check CPU/GPU usage**:

   ```powershell
   # Monitor during processing
   nvidia-smi -l 1  # GPU usage
   Task Manager ‚Üí Performance  # CPU usage
   ```

4. **Benchmark your system**:

   ```powershell
   # Test CPU mode
   Measure-Command { python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\test.json --yolo-device cpu --donut-device cpu }

   # Test GPU mode
   Measure-Command { python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\test.json --yolo-device cuda --donut-device cuda }
   ```

#### Problem: First run sangat lambat, subsequent runs normal

**Cause**: Model loading overhead (normal behavior)

**Explanation**:

- First run: Load YOLO model (~50MB) + Donut model (~500MB) = ~4-6s overhead
- Subsequent runs: Models cached di memory = stable performance

**Solutions untuk Production**:

1. **Warm-up inference** at startup:

   ```python
   # Dummy inference untuk pre-load models
   dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)
   process_image(dummy_img, yolo_model, donut_processor, donut_model)
   ```

2. **Keep models in memory** (jangan recreate per request)

3. **Use model caching** di server/API:

   ```python
   # Load models once at server startup
   yolo_model = YOLO("best.pt")
   donut_processor, donut_model = load_donut_model("donut-ktp-v3")

   # Reuse untuk all requests
   @app.route("/ocr", methods=["POST"])
   def ocr_endpoint():
       result = process_image(image, yolo_model, donut_processor, donut_model)
       return jsonify(result)
   ```

### Output Issues

#### Problem: JSON output tidak valid atau corrupt

**Solutions**:

1. **Check error messages** di console output

2. **Validate JSON**:

   ```powershell
   python -m json.tool outputs\results.json
   ```

3. **Check file permissions** (write access to outputs/ folder)

4. **Try different output path**:
   ```powershell
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output C:\temp\results.json
   ```

#### Problem: Banyak fields return null

**Possible Causes**:

1. Image quality rendah
2. Confidence threshold terlalu strict
3. KTP layout tidak standard

**Solutions**:

1. **Check field confidence scores**:

   ```json
   "metadata": {
     "field_confidence": {
       "nik": 1.0,    // OK
       "nama": 0.5,   // Below threshold (0.7)
       "alamat": 0.4  // Below threshold (0.6)
     }
   }
   ```

2. **Lower thresholds** di `process_ktp_json.py`

3. **Check raw OCR text**:

   ```python
   import json
   data = json.load(open("outputs/results.json"))
   print(data["metadata"]["raw_ocr_text"])
   ```

4. **Enable fallback**:
   ```powershell
   python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\results.json --enable-fallback
   ```

## Performance

### Benchmark Results (7 Sample Images)

| Configuration                 | Total Time | Per Image | Throughput | Speedup  |
| ----------------------------- | ---------- | --------- | ---------- | -------- |
| **CPU Mode**                  | 30.21s     | ~4.32s    | 0.23 img/s | 1.0x     |
| **GPU Mode** (RTX 4070 SUPER) | 14.39s     | ~2.06s    | 0.49 img/s | **2.1x** |

- **Hardware**: NVIDIA GeForce RTX 4070 SUPER (12GB VRAM), Intel i7/Ryzen 7
- **Software**: PyTorch 2.5.1+cu121, CUDA 12.1
- **Dataset**: datasets/sample_ocr_ktp_axa (7 images, mixed quality)
- **Metrics**: Measured with PowerShell Measure-Command (includes model loading)

### Performance Tips

1. **Use GPU for batch processing** (10+ images) ‚Üí 2.1x speedup
2. **Disable fallback** (default) ‚Üí 2x faster processing
3. **Pre-load models** untuk avoid first-run overhead
4. **Use hybrid mode** (YOLO GPU, Donut CPU) jika VRAM limited
5. **Optimize image size** (640-1280px width optimal)

Detail lengkap: [BENCHMARK.md](docs/BENCHMARK.md)

## Known Limitations

‚ö†Ô∏è **Field `pekerjaan`**: Model tidak trained untuk field ini (detection rate: 0%). Solusi:

- Enable PaddleOCR fallback (--enable-fallback)
- Retrain Donut model dengan annotated samples
- Manual extraction dari raw_ocr_text

‚ö†Ô∏è **PaddlePaddle compatibility**: Version 2.6+ conflict dengan PyTorch 2.5+. System works without it, tetapi header OCR (provinsi/kota) affected.

‚ö†Ô∏è **Vertical KTP**: Auto-rotation implemented, tapi akurasi bisa turun 10-15%.

‚ö†Ô∏è **Low-quality images**: Minimal resolution 640x480, good lighting required.

## Key Improvements

See [IMPROVEMENTS.md](docs/IMPROVEMENTS.md) for detailed changelog:

### Header OCR Enhancement

- **PaddleOCR integration**: Single-region OCR (~30% top strip) untuk accurate provinsi/kota extraction
- **Split merged tokens**: Auto-split typos seperti "KOTAMEDAN" ‚Üí "KOTA MEDAN"
- **Typo normalization**: Fix common OCR errors (e.g., "PHUVINSI" ‚Üí "PROVINSI", "KUTA" ‚Üí "KOTA")
- **Regex with lookaheads**: Stop over-capture di NIK/NAMA/TEMPAT/TTL boundaries

### Field Parsing Enhancement

- **Canonical province mapping**: Fuzzy match untuk handle variations (e.g., "SUMATERA UTA" ‚Üí "SUMATERA UTARA")
- **Kota cleaner**: Drop trailing noise (e.g., names, stray letters), preserve valid multi-word cities
- **Position-based extraction**: Alamat (RT/RW anchor), Pekerjaan (after status_perkawinan/agama)
- **Multi-level confidence**: YOLO detection + OCR token probability + per-field validation

### Performance Optimization

- **GPU acceleration**: PyTorch CUDA support (2.1x speedup on RTX 4070 SUPER)
- **Optimized fallback**: Single-pass PaddleOCR dengan lightweight preprocessing (37% faster)
- **Lazy loading**: Models loaded once dan cached untuk subsequent requests
- **Flexible device selection**: Independent device control untuk YOLO, Donut, PaddleOCR

### Architecture Improvements

- **Modular design**: Separate YOLO detection, Donut OCR, field parsing
- **Graceful degradation**: System works tanpa PaddleOCR jika import conflict
- **Comprehensive diagnostics**: Device logging, timing analysis, error reporting
- **Thresholded output**: Confidence-based filtering untuk production-ready results

## Development

### Setup Development Environment

```powershell
# 1. Clone repository
git clone https://github.com/your-org/afi-ocr-ktp-code.git
cd afi-ocr-ktp-code

# 2. Create virtual environment
python -m venv .venv_system
.\.venv_system\Scripts\Activate.ps1

# 3. Install dependencies
pip install -r requirements.txt

# 4. (Optional) Install GPU support
.\install_gpu.ps1

# 5. Verify installation
python scripts\diagnostics\check_cuda.py
```

### Running Tests

```powershell
# Test single image
python run_ocr.py --mode file --input datasets\sample_ocr_ktp_axa\ktp_001.jpg --output outputs\test.json

# Test batch processing
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\test_batch.json

# Test camera mode
python run_ocr.py --mode camera
```

### Diagnostic Tools

#### 1. Check CUDA and GPU Status

```powershell
python scripts\diagnostics\check_cuda.py
```

Output:

- ‚úì NVIDIA Driver version
- ‚úì PyTorch CUDA availability
- ‚úì GPU device name dan compute capability
- ‚úì PaddlePaddle GPU status
- ‚úì Ultralytics YOLO installation

#### 2. Inspect Header OCR Results

```powershell
python tools\diagnostics\show_headers.py outputs\results.json
```

Display:

- Header OCR raw text
- Parsed provinsi line
- Parsed kota line
- Per-image breakdown

#### 3. Analyze Processing Timing

```powershell
python tools\diagnostics\show_timing.py
```

Show:

- Total processing time
- Average time per image
- Min/max timing
- Timing breakdown (if available)

#### 4. YOLO Detection Viewer

```powershell
python tools\diagnostics\process_yolo_optimized.py
```

Features:

- Real-time YOLO detection
- FPS counter
- Bounding box visualization
- No OCR overhead (fast testing)

### Code Structure

**Main Processing Pipeline** (`run_ocr.py`):

```python
def main():
    # 1. Parse CLI arguments
    args = parse_arguments()

    # 2. Load models (YOLO, Donut, PaddleOCR)
    yolo_model, donut_processor, donut_model, paddle_ocr = load_models(args)

    # 3. Process based on mode
    if args.mode == "file":
        result = process_image(...)
    elif args.mode == "folder":
        results = process_image_folder(...)
    elif args.mode == "camera":
        process_camera(...)

    # 4. Save results to JSON
    save_results(results, args.output)
```

**Core OCR Logic** (`process_ktp_json.py`):

```python
def process_image(img, yolo_model, donut_processor, donut_model, paddle_ocr=None, enable_fallback=False):
    # 1. YOLO detection (crop KTP region)
    cropped_img, yolo_confidence = detect_ktp_card(img, yolo_model)

    # 2. Donut OCR (extract raw text)
    raw_text, ocr_confidence = donut_ocr(cropped_img, donut_processor, donut_model)

    # 3. (Optional) PaddleOCR header parsing
    if paddle_ocr:
        header_text = paddle_header_ocr(cropped_img, paddle_ocr)
        provinsi, kota = parse_header_fields(header_text)

    # 4. Parse fields dengan confidence scoring
    fields = parse_ktp_fields(raw_text, provinsi, kota)
    field_confidence = calculate_field_confidence(fields)

    # 5. Apply confidence thresholds
    filtered_fields = apply_confidence_thresholds(fields, field_confidence)

    # 6. Return structured result
    return {
        "status": "success",
        "metadata": {...},
        "data": filtered_fields
    }
```

### Extending the System

#### Add New Field Extraction

Edit `process_ktp_json.py`:

```python
def parse_ktp_fields(raw_text, provinsi=None, kota=None):
    fields = {}

    # ... existing field extraction ...

    # Add new field extraction
    fields["new_field"] = extract_new_field(raw_text)

    return fields

def extract_new_field(raw_text):
    # Implement extraction logic
    pattern = r"NEW_FIELD_PATTERN"
    match = re.search(pattern, raw_text)
    if match:
        return match.group(1)
    return None
```

Add confidence threshold:

```python
FIELD_CONFIDENCE_THRESHOLDS = {
    # ... existing thresholds ...
    "new_field": 0.7,  # Add threshold for new field
}
```

#### Retrain Donut Model

Untuk improve accuracy atau add new fields:

1. **Prepare annotated dataset** (JSON format):

   ```json
   {
     "ground_truth": "{\"nik\": \"1234567890123456\", \"nama\": \"JOHN DOE\", ...}",
     "image_path": "path/to/ktp.jpg"
   }
   ```

2. **Fine-tune Donut model**:

   ```python
   from transformers import VisionEncoderDecoderModel, DonutProcessor

   # Load base model
   model = VisionEncoderDecoderModel.from_pretrained("donut-ktp-v3")
   processor = DonutProcessor.from_pretrained("donut-ktp-v3")

   # Fine-tune dengan new dataset
   # (See Donut documentation: https://github.com/clovaai/donut)
   ```

3. **Evaluate performance**:

   ```powershell
   # Test dengan validation set
   python run_ocr.py --mode folder --input datasets\validation --output outputs\eval.json

   # Compare results
   python tools\evaluation\compare_results.py outputs\eval.json datasets\ground_truth.json
   ```

#### Integrate with API

Example Flask API:

```python
from flask import Flask, request, jsonify
from process_ktp_json import process_image
from ultralytics import YOLO
from transformers import VisionEncoderDecoderModel, DonutProcessor
import cv2
import numpy as np

app = Flask(__name__)

# Load models once at startup (keep in memory)
print("Loading models...")
yolo_model = YOLO("best.pt")
donut_processor = DonutProcessor.from_pretrained("donut-ktp-v3")
donut_model = VisionEncoderDecoderModel.from_pretrained("donut-ktp-v3")
donut_model = donut_model.to("cuda" if torch.cuda.is_available() else "cpu")
print("Models loaded!")

@app.route("/ocr", methods=["POST"])
def ocr_endpoint():
    try:
        # Get image dari request
        file = request.files["image"]
        img_bytes = file.read()
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        # Process image
        result = process_image(img, yolo_model, donut_processor, donut_model)

        return jsonify(result), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

Run server:

```powershell
python api_server.py
```

Test API:

```powershell
curl -X POST -F "image=@path\to\ktp.jpg" http://localhost:5000/ocr
```

## FAQ

### General Questions

**Q: Apakah sistem ini bisa process KTP blur atau low-quality?**

A: Sistem sudah include preprocessing (CLAHE, sharpening, denoising), tapi ada batas minimal:

- Resolution minimal: 640x480 pixels
- Lighting: Avoid shadows atau glare
- Focus: Text harus readable (tidak terlalu blur)
- Orientation: Max 15¬∞ skew (auto-rotation untuk vertical KTPs)

**Q: Berapa akurasi sistem ini?**

A: Berdasarkan sample dataset (7 images):

- Overall success rate: 100% (7/7 images berhasil di-process)
- Field detection rate:
  - High confidence fields (NIK, Nama, Tanggal Lahir): 95-100%
  - Medium confidence fields (Alamat, Kel/Desa): 80-90%
  - Low confidence fields (Pekerjaan): 0-20% (model limitation)
- Provinsi/Kota (dengan PaddleOCR): 85-100%

**Q: Apakah bisa process KTP format lama?**

A: Model trained pada format KTP terbaru (electronic KTP). Format lama mungkin tidak detected atau accuracy rendah. Perlu retrain model jika support format lama required.

**Q: Support multi-threading atau parallel processing?**

A: Current implementation sequential. Untuk parallel processing:

- Use Python multiprocessing (spawn multiple processes)
- Deploy multiple instances behind load balancer
- Use batch processing dengan GPU (faster untuk large batches)

### GPU and Performance

**Q: GPU saya tidak support CUDA 12.1, apa solusinya?**

A: Install PyTorch dengan CUDA version yang sesuai GPU Anda:

```powershell
# Check GPU compute capability
nvidia-smi --query-gpu=compute_cap --format=csv

# Install PyTorch dengan CUDA 11.8 (untuk older GPUs)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Q: Berapa VRAM yang dibutuhkan?**

A:

- Minimum: 2 GB VRAM (YOLO only atau Donut only)
- Recommended: 4 GB VRAM (YOLO + Donut)
- Tested: 1.7 GB actual usage pada RTX 4070 SUPER

**Q: Kenapa GPU mode hanya 2.1x faster, not 10x or more?**

A:

- Model size: Donut model besar (~500MB), overhead loading dan inference
- I/O bound: Image reading/writing tetap CPU-bound
- Preprocessing: OpenCV operations di CPU (CLAHE, resize, etc.)
- Single image: Batch processing lebih efficient untuk GPU (current: sequential)
- Optimization potential: Future improvements (TensorRT, ONNX, batching)

**Q: Apakah bisa run di laptop tanpa dedicated GPU?**

A: Yes, CPU mode fully supported:

- Processing time: ~4.3s per image (Intel i7 / Ryzen 7)
- No CUDA installation required
- Install dengan `pip install -r requirements.txt` (CPU version)
- Suitable untuk low-volume usage (<100 images per day)

### Integration and Deployment

**Q: Bagaimana cara integrate dengan existing system?**

A: Beberapa options:

1. **REST API**: Deploy Flask/FastAPI server (contoh di [Extending the System](#extending-the-system))
2. **Python module**: Import `process_ktp_json.py` dan call `process_image()` directly
3. **CLI batch**: Run `run_ocr.py` dari existing scripts
4. **Docker container**: Containerize untuk easy deployment

**Q: Apakah support cloud deployment (AWS, Azure, GCP)?**

A: Yes, recommendations:

- **AWS**: EC2 dengan GPU (p3.2xlarge atau g4dn.xlarge), Lambda untuk CPU-only
- **Azure**: VM dengan NVIDIA GPU, Batch AI untuk distributed processing
- **GCP**: Compute Engine dengan GPU, AI Platform untuk managed deployment
- **Docker**: Build image dengan dependencies dan models pre-loaded

**Q: Bagaimana cara handle concurrent requests?**

A:

1. **Single server**: Use async framework (FastAPI + async/await)
2. **Load balancing**: Deploy multiple instances behind nginx/HAProxy
3. **Queue system**: Celery + Redis untuk async job processing
4. **Kubernetes**: Auto-scaling pods based on load

Example dengan Celery:

```python
from celery import Celery

app = Celery('ocr_tasks', broker='redis://localhost:6379')

@app.task
def process_ktp_task(image_path):
    img = cv2.imread(image_path)
    result = process_image(img, yolo_model, donut_processor, donut_model)
    return result

# Submit task
task = process_ktp_task.delay("/path/to/ktp.jpg")
result = task.get()  # Wait for result
```

### Troubleshooting

**Q: Kenapa processing pertama kali sangat lambat?**

A: Normal behavior - model loading overhead:

- First run: ~6-8s (load YOLO + Donut models)
- Subsequent runs: ~2-4s (models cached)
- Solution: Pre-load models dengan dummy inference (warmup)

**Q: Field confidence selalu rendah, kenapa?**

A: Possible causes:

1. Image quality rendah ‚Üí Improve lighting/resolution
2. Threshold terlalu strict ‚Üí Lower thresholds di `process_ktp_json.py`
3. Non-standard KTP layout ‚Üí Check `raw_ocr_text` untuk debug
4. Model limitation ‚Üí Consider retraining dengan more samples

**Q: Bagaimana cara debug jika hasil tidak sesuai?**

A: Step-by-step debugging:

1. **Check YOLO detection**: Use `process_yolo_optimized.py` untuk verify crop
2. **Check raw OCR text**: Print `metadata.raw_ocr_text` dari JSON output
3. **Check header OCR**: Run `show_headers.py` untuk see header parsing
4. **Check field confidence**: Review `metadata.field_confidence` scores
5. **Enable debug logging**: Set environment variable `OCR_DEBUG=1`

**Q: Support untuk OS lain (Linux, macOS)?**

A: Codebase cross-platform, tapi:

- **Linux**: Fully supported (tested on Ubuntu 20.04+)
- **macOS**: Supported untuk CPU mode (MPS backend experimental)
- **Windows**: Fully tested dan recommended (current documentation)

Adjust commands untuk shell Anda:

```bash
# Linux/macOS activation
source .venv_system/bin/activate

# Run OCR
python run_ocr.py --mode folder --input datasets/sample_ocr_ktp_axa --output outputs/results.json
```

## Contributing

We welcome contributions! Please follow these guidelines:

### How to Contribute

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/your-feature-name`
3. **Make changes**: Implement your feature or fix
4. **Test thoroughly**: Run tests dan verify tidak break existing functionality
5. **Commit changes**: `git commit -m "Add: your feature description"`
6. **Push to branch**: `git push origin feature/your-feature-name`
7. **Submit Pull Request**: Create PR dengan detailed description

### Code Style

- Follow PEP 8 Python style guide
- Use meaningful variable/function names
- Add docstrings untuk functions dan classes
- Comment complex logic
- Keep functions focused (single responsibility)

### Testing

Before submitting PR:

```powershell
# Test all modes
python run_ocr.py --mode file --input datasets\sample_ocr_ktp_axa\test.jpg --output outputs\test.json
python run_ocr.py --mode folder --input datasets\sample_ocr_ktp_axa --output outputs\test_batch.json
python run_ocr.py --mode camera

# Verify GPU support (if applicable)
python scripts\diagnostics\check_cuda.py

# Check for errors
python -m pylint run_ocr.py process_ktp_json.py
```

### Areas for Improvement

Priority contributions:

- [ ] Fix PaddlePaddle + PyTorch compatibility issue
- [ ] Improve `pekerjaan` field detection (retrain model)
- [ ] Add batching support untuk GPU (process multiple images simultaneously)
- [ ] Implement TensorRT/ONNX optimization untuk faster inference
- [ ] Add unit tests dan integration tests
- [ ] Support untuk KTP format lama
- [ ] Web UI untuk easy testing
- [ ] Docker containerization
- [ ] REST API dengan authentication
- [ ] Logging dan monitoring (Prometheus, Grafana)

## License

[Specify your license here - e.g., MIT, Apache 2.0, Proprietary]

## Changelog

### Version 2.1 (Current) - December 2024

**Features**:

- ‚úÖ GPU acceleration support (PyTorch CUDA)
- ‚úÖ Flexible device selection (YOLO, Donut independent)
- ‚úÖ Optimized PaddleOCR fallback (single-pass, 37% faster)
- ‚úÖ Comprehensive diagnostics (check_cuda.py)
- ‚úÖ Automated GPU installer (install_gpu.ps1)
- ‚úÖ Performance benchmarks (BENCHMARK.md)
- ‚úÖ Complete installation documentation

**Performance**:

- GPU mode: 2.1x speedup vs CPU (RTX 4070 SUPER)
- Fallback optimization: 141s vs 223s (37% faster)
- Throughput: 0.49 img/s (GPU) vs 0.23 img/s (CPU)

**Known Issues**:

- PaddlePaddle 2.6+ import conflict dengan PyTorch 2.5+ (workaround: disable PaddleOCR)
- Field `pekerjaan` low detection rate (model limitation)

### Version 2.0 - November 2024

**Features**:

- Header OCR dengan PaddleOCR (provinsi/kota extraction)
- Multi-level confidence scoring
- Thresholded output (confidence-based filtering)
- Position-based field extraction (alamat, pekerjaan)
- Fuzzy matching untuk canonicalization

### Version 1.0 - October 2024

**Initial Release**:

- YOLO detection + Donut OCR
- Basic field parsing
- Camera mode support
- JSON output format

## Contact

For questions, issues, or feature requests:

- **GitHub Issues**: [Create an issue](https://github.com/your-org/afi-ocr-ktp-code/issues)
- **Email**: your-email@example.com
- **Documentation**: [Wiki](https://github.com/your-org/afi-ocr-ktp-code/wiki)

---

**Version**: 2.1  
**Last Updated**: December 2024  
**Tested on**: Windows 11, Python 3.11, PyTorch 2.5.1+cu121, RTX 4070 SUPER

## Quick Reference

### Common Commands

```powershell
# Activate environment
.\.venv_system\Scripts\Activate.ps1

# Single image (CPU)
python run_ocr.py --mode file --input image.jpg --output result.json

# Batch (GPU)
python run_ocr.py --mode folder --input input_folder --output results.json --yolo-device cuda --donut-device cuda

# Camera (GPU)
python run_ocr.py --mode camera --yolo-device cuda --donut-device cuda

# Check GPU
python scripts\diagnostics\check_cuda.py

# Install GPU
.\install_gpu.ps1

# Inspect results
python tools\diagnostics\show_headers.py outputs\results.json
```

### Git Quick Commands

```powershell
# Fetch latest changes (no merge)
git fetch origin

# Pull latest main (fetch + merge)
git pull origin main

# Commit and push your changes
git add .
git commit -m "docs: update README quick commands"
git push origin main

# See recent history (last 5 commits)
git log --oneline -5
```

Notes:

- models/ and outputs/ are ignored by git. After a fresh clone/pull, make sure your model files exist under `models/` before running.
- If needed, copy models from your backup location:

  ```powershell
  Copy-Item -Path "C:\afi-ocr-ktp-code\donut-ktp-v3" -Destination "models\" -Recurse -Force
  Copy-Item -Path "C:\afi-ocr-ktp- code\best.pt" -Destination "models\" -Force
  ```

### File Locations

- **Models**: `models/best.pt` (YOLO), `models/donut-ktp-v3/` (Donut)
- **Config**: `process_ktp_json.py` (thresholds, parsing logic)
- **Output**: `outputs/` (JSON results)
- **Samples**: `datasets/sample_ocr_ktp_axa/` (test images)
- **Diagnostics**: `scripts/diagnostics/` (diagnostic tools)
- **Documentation**: `docs/` (BENCHMARK.md, IMPROVEMENTS.md)

### Support

- **Documentation**: This README + [BENCHMARK.md](docs/BENCHMARK.md) + [IMPROVEMENTS.md](docs/IMPROVEMENTS.md)
- **Issues**: Check [Troubleshooting](#troubleshooting) section first
- **Diagnostics**: Run `python scripts\diagnostics\check_cuda.py` untuk GPU issues
- **Performance**: See [BENCHMARK.md](docs/BENCHMARK.md) untuk optimization tips
